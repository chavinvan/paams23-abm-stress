{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning of the approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler, NeighbourhoodCleaningRule\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_classifier(clf_name):\n",
    "    if clf_name == 'LogR':\n",
    "        return LogisticRegression(max_iter=1500000, random_state=24091993)\n",
    "    elif clf_name == 'DT':\n",
    "        return DecisionTreeClassifier(random_state=24091993)\n",
    "    elif clf_name == 'RF':\n",
    "        return RandomForestClassifier(random_state=24091993)\n",
    "    elif clf_name == 'ADA':\n",
    "        return AdaBoostClassifier(random_state=24091993, estimator=LogisticRegression(max_iter=1500000, random_state=24091993))\n",
    "    \n",
    "\n",
    "def select_params(clf_name):\n",
    "    if clf_name == 'LogR':\n",
    "        return {'C': np.logspace(-3,2, num=10),}\n",
    "    elif clf_name == 'LinSVM':\n",
    "        return {'C': np.logspace(-3,2, num=10), }\n",
    "    elif clf_name == 'DT':\n",
    "        return {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "    elif clf_name == 'RF':\n",
    "        return {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion' :['gini', 'entropy']}\n",
    "    elif clf_name == 'ADA':\n",
    "        return {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200], 'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "\n",
    "def create_features(data, window_size=2):\n",
    "    data['date'] = data['date'].astype('datetime64[ns]')\n",
    "    data['weekday'] = data['date'].dt.weekday\n",
    "    \n",
    "    # add a new column with the average value of the last two rows of other column\n",
    "    wl_sum = 0\n",
    "    sp_sum = 0\n",
    "    voice_sum = 0\n",
    "    wl_values = []\n",
    "    sp_values = []\n",
    "    voice_values = []\n",
    "    wl_delta = pd.Series(dtype='float64')\n",
    "    sp_delta = pd.Series(dtype='float64')\n",
    "    voice_delta = pd.Series(dtype='float64')\n",
    "    for i in range(0, window_size):\n",
    "        workload = data.groupby('user')['workload'].shift(i)\n",
    "        sleep = data.groupby('user')['sleep'].shift(i)\n",
    "        voice = data.groupby('user')['voice'].shift(i)\n",
    "        wl_sum += workload\n",
    "        wl_values.append(workload)\n",
    "        sp_sum += sleep\n",
    "        sp_values.append(sleep)\n",
    "        voice_sum += voice\n",
    "        voice_values.append(voice)\n",
    "        wl_delta = workload if wl_delta.empty else wl_delta - workload\n",
    "        sp_delta = sleep if sp_delta.empty else sp_delta - sleep\n",
    "        voice_delta = voice if voice_delta.empty else voice_delta - voice        \n",
    "\n",
    "    if window_size > 2:\n",
    "        stress_sum = 0\n",
    "        stress_values = []\n",
    "        stress_delta = pd.Series(dtype='float64')\n",
    "\n",
    "        for i in range(1, window_size):\n",
    "            stress = data.groupby('user')['stress'].shift(i)\n",
    "            stress_sum += stress\n",
    "            stress_values.append(stress)\n",
    "            stress_delta = stress if stress_delta.empty else stress_delta - stress\n",
    "\n",
    "    data['prev_stress'] = data.groupby('user')['stress'].shift(1)\n",
    "    \n",
    "    \n",
    "    if window_size > 1:\n",
    "        data['wl_avg_{}'.format(window_size)] = wl_sum / window_size\n",
    "        data['sp_avg_{}'.format(window_size)] = sp_sum / window_size\n",
    "        data['wl_std_{}'.format(window_size)] = np.std(wl_values, axis=0)\n",
    "        data['sp_std_{}'.format(window_size)] = np.std(sp_values, axis=0)\n",
    "        data['wl_max_{}'.format(window_size)] = np.max(wl_values, axis=0)\n",
    "        data['sp_max_{}'.format(window_size)] = np.max(sp_values, axis=0)\n",
    "        data['wl_min_{}'.format(window_size)] = np.min(wl_values, axis=0)\n",
    "        data['sp_min_{}'.format(window_size)] = np.min(sp_values, axis=0)\n",
    "        data['wl_delta_{}'.format(window_size)] = wl_delta\n",
    "        data['sp_delta_{}'.format(window_size)] = sp_delta\n",
    "        \n",
    "        \n",
    "        data['voice_avg_{}'.format(window_size)] = voice_sum / window_size\n",
    "        data['voice_std_{}'.format(window_size)] = np.std(voice_values, axis=0)\n",
    "        data['voice_max_{}'.format(window_size)] = np.max(voice_values, axis=0)\n",
    "        data['voice_min_{}'.format(window_size)] = np.min(voice_values, axis=0)\n",
    "        data['voice_delta_{}'.format(window_size)] = voice_delta\n",
    "\n",
    "        if window_size > 2:\n",
    "            data['stress_avg_{}'.format(window_size)] = stress_sum / (window_size-1)\n",
    "            data['stress_std_{}'.format(window_size)] = np.std(stress_values, axis=0)\n",
    "            data['stress_max_{}'.format(window_size)] = np.max(stress_values, axis=0)\n",
    "            data['stress_min_{}'.format(window_size)] = np.min(stress_values, axis=0)\n",
    "            data['stress_delta_{}'.format(window_size)] = stress_delta\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strategies = ['balanced']\n",
    "\n",
    "datasets = {\n",
    "    'sl' : {\n",
    "        'cut_strategies' : [''],\n",
    "        'weeks' : {\n",
    "            'balanced' : {\n",
    "                'start' : 13,\n",
    "                'length' : 7,\n",
    "                'train_lengths': [5, 6] \n",
    "            },\n",
    "            'reliable' : {\n",
    "                'start' : 13,\n",
    "                'length' : 4,\n",
    "                'train_lengths': [2, 3] \n",
    "            },\n",
    "        },\n",
    "        'max_missing_percentages' : [75]\n",
    "\n",
    "    },\n",
    "    'fbk' : {\n",
    "        'cut_strategies' : ['_notcut'],\n",
    "        'weeks' : {\n",
    "            'balanced' : {\n",
    "                'start' : 45,\n",
    "                'length' : 7,\n",
    "                'train_lengths': [5, 6] \n",
    "            },\n",
    "            'reliable' : {\n",
    "                'start' : 46,\n",
    "                'length' : 5,\n",
    "                'train_lengths': [3, 4] \n",
    "            },\n",
    "        },\n",
    "        'max_missing_percentages' : [60]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset_name, cut_strategy, max_missing_percentage, data_strategy, ws, dataset):\n",
    "    scores = []\n",
    "    for clf_name in ['RF']:\n",
    "        np.random.seed(24091993)\n",
    "        cv = StratifiedKFold(shuffle=True, n_splits=5, random_state=24091993)\n",
    "        clf = select_classifier(clf_name)\n",
    "        params = select_params(clf_name)\n",
    "        \n",
    "        data = dataset.copy()\n",
    "\n",
    "        X = data.drop(['stress', 'date', 'duration','user'], axis=1)#data[['sleep', 'workload', 'weekday', 'prev_stress', 'voice', 'weekday']]\n",
    "        cols = X.columns\n",
    "        y = data['stress']\n",
    "        \n",
    "        \n",
    "        # undersample = NeighbourhoodCleaningRule(sampling_strategy='not minority')\n",
    "        # fit and apply the transform\n",
    "        # X, y = undersample.fit_resample(X, y)\n",
    "        \n",
    "        rscv = RandomizedSearchCV(clf, params, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "        rscv.fit(X, y)\n",
    "        scores.append([dataset_name, clf_name, rscv.best_params_, rscv.best_score_,  max_missing_percentage, data_strategy, ws, cut_strategy, cols])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_array = []\n",
    "for dataset_name in ['sl', 'fbk']:\n",
    "    for cut_strategy in datasets[dataset_name]['cut_strategies']:\n",
    "        for max_missing_percentage in datasets[dataset_name]['max_missing_percentages']:\n",
    "            for data_strategy in data_strategies:\n",
    "                dataframe = pd.read_csv('../data/processed/{}_processed_data_{}_{}{}.csv'.format(dataset_name, max_missing_percentage, data_strategy, cut_strategy))\n",
    "                data = dataframe.copy()\n",
    "                data = create_features(data, window_size=2)\n",
    "                data.dropna(inplace=True)\n",
    "                scores = evaluate(dataset_name, cut_strategy, max_missing_percentage, data_strategy, 2, data)\n",
    "                scores = pd.DataFrame(scores, columns=['dataset', 'classifier','params', 'score', 'max_missing_percentage', 'data_strategy', 'ws', 'cut_strategy', 'features'])\n",
    "                scores_array.append(scores)\n",
    "scores = pd.concat(scores_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>classifier</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "      <th>max_missing_percentage</th>\n",
       "      <th>data_strategy</th>\n",
       "      <th>ws</th>\n",
       "      <th>cut_strategy</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fbk</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'n_estimators': 120, 'max_depth': 6, 'criteri...</td>\n",
       "      <td>0.759557</td>\n",
       "      <td>60</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>_notcut</td>\n",
       "      <td>Index(['workload', 'sleep', 'voice', 'weekday'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sl</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'n_estimators': 80, 'max_depth': 10, 'criteri...</td>\n",
       "      <td>0.752359</td>\n",
       "      <td>75</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>Index(['workload', 'sleep', 'voice', 'weekday'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset classifier                                             params  \\\n",
       "0     fbk         RF  {'n_estimators': 120, 'max_depth': 6, 'criteri...   \n",
       "0      sl         RF  {'n_estimators': 80, 'max_depth': 10, 'criteri...   \n",
       "\n",
       "      score  max_missing_percentage data_strategy  ws cut_strategy  \\\n",
       "0  0.759557                      60      balanced   2      _notcut   \n",
       "0  0.752359                      75      balanced   2                \n",
       "\n",
       "                                            features  \n",
       "0  Index(['workload', 'sleep', 'voice', 'weekday'...  \n",
       "0  Index(['workload', 'sleep', 'voice', 'weekday'...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(by=['score'], ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with the fine-tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02517346 0.02842446 0.02897885 0.09050737 0.38226862 0.0323143\n",
      " 0.03561193 0.01497267 0.02499668 0.02530832 0.02482898 0.02303304\n",
      " 0.02487759 0.02583235 0.0347456  0.05091746 0.03168468 0.03220943\n",
      " 0.0292124  0.03410179]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72        88\n",
      "           2       0.82      0.83      0.82       265\n",
      "           3       0.84      0.82      0.83       179\n",
      "\n",
      "    accuracy                           0.81       532\n",
      "   macro avg       0.79      0.79      0.79       532\n",
      "weighted avg       0.81      0.81      0.81       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = select_classifier(scores[scores['dataset'] == 'sl'].query('score == score.max()').iloc[0]['classifier'])\n",
    "clf.set_params(**scores[scores['dataset'] == 'sl'].query('score == score.max()').iloc[0]['params'])\n",
    "data = pd.read_csv('../data/processed/sl_processed_data_75_balanced.csv')\n",
    "data = create_features(data, window_size=2)\n",
    "data.dropna(inplace=True)\n",
    "data['prev_stress'] = data['prev_stress'].astype(int)\n",
    "data['week'] = data['date'].astype('datetime64[ns]').dt.isocalendar().week\n",
    "training_data = data[(data['week'] >= 13) & (data['week'] <= 17)]\n",
    "test_data = data[(data['week'] >= 18) & (data['week'] < 20)]\n",
    "X_train = training_data.drop(['stress', 'date', 'duration','user', 'week'], axis=1).values\n",
    "y_train = training_data['stress']\n",
    "\n",
    "# undersample = NeighbourhoodCleaningRule(sampling_strategy='not minority')\n",
    "# fit and apply the transform\n",
    "# X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(test_data.drop(['stress', 'date', 'duration','user', 'week'], axis=1).values)\n",
    "y_true = test_data['stress']\n",
    "print(clf.feature_importances_)\n",
    "print(classification_report(y_true, y_pred))\n",
    "pickle.dump(clf, open('../trained_models/sl_data_75_balanced_model_trained.pickle', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.68      0.74       343\n",
      "           2       0.82      0.81      0.81       608\n",
      "           3       0.76      0.91      0.83       341\n",
      "\n",
      "    accuracy                           0.80      1292\n",
      "   macro avg       0.80      0.80      0.80      1292\n",
      "weighted avg       0.80      0.80      0.80      1292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(training_data['stress'], clf.predict(training_data.drop(['stress', 'date', 'duration', 'user', 'week'], axis=1).values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.90      0.89       100\n",
      "           2       0.76      0.80      0.78        59\n",
      "           3       0.83      0.67      0.74        30\n",
      "\n",
      "    accuracy                           0.83       189\n",
      "   macro avg       0.82      0.79      0.80       189\n",
      "weighted avg       0.83      0.83      0.83       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(criterion='entropy', max_depth=9, n_estimators=30, random_state=24091993)\n",
    "clf2 = LogisticRegression(max_iter=1500000, random_state=24091993, C=27.825594022071257)\n",
    "clf = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=80,\n",
    "                       random_state=24091993)\n",
    "data = pd.read_csv('../data/processed/fbk_processed_data_60_balanced_notcut.csv')\n",
    "data = create_features(data, window_size=2)\n",
    "data.dropna(inplace=True)\n",
    "data['week'] = data['date'].astype('datetime64[ns]').dt.isocalendar().week\n",
    "training_data = data[(data['week'] >= 45) & (data['week'] <= 45 + 6 - 1)]\n",
    "test_data = data[(data['week'] >= 45 + 6) & (data['week'] < 45 + 7)]\n",
    "clf.fit(training_data.drop(['stress', 'date', 'duration', 'user', 'week'], axis=1).values, training_data['stress'])\n",
    "y_pred = clf.predict(test_data.drop(['stress', 'date', 'duration', 'user', 'week'], axis=1).values)\n",
    "y_true = test_data['stress']\n",
    "print(classification_report(y_true, y_pred))\n",
    "pickle.dump(clf, open('../trained_models/fbk_data_60_balanced_notcut_model_trained.pickle', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workload</th>\n",
       "      <th>sleep</th>\n",
       "      <th>voice</th>\n",
       "      <th>weekday</th>\n",
       "      <th>prev_stress</th>\n",
       "      <th>wl_avg_2</th>\n",
       "      <th>sp_avg_2</th>\n",
       "      <th>wl_std_2</th>\n",
       "      <th>sp_std_2</th>\n",
       "      <th>wl_max_2</th>\n",
       "      <th>sp_max_2</th>\n",
       "      <th>wl_min_2</th>\n",
       "      <th>sp_min_2</th>\n",
       "      <th>wl_delta_2</th>\n",
       "      <th>sp_delta_2</th>\n",
       "      <th>voice_avg_2</th>\n",
       "      <th>voice_std_2</th>\n",
       "      <th>voice_max_2</th>\n",
       "      <th>voice_min_2</th>\n",
       "      <th>voice_delta_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      workload  sleep  voice  weekday  prev_stress  wl_avg_2  sp_avg_2  \\\n",
       "1            3      3      4        1          2.0       3.0       3.0   \n",
       "2            3      3      4        2          2.0       3.0       3.0   \n",
       "3            3      3      4        3          2.0       3.0       3.0   \n",
       "4            3      3      4        4          2.0       3.0       3.0   \n",
       "5            3      3      4        5          2.0       3.0       3.0   \n",
       "...        ...    ...    ...      ...          ...       ...       ...   \n",
       "1311         5      2      5        2          1.0       4.5       3.5   \n",
       "1312         5      2      5        3          2.0       5.0       2.0   \n",
       "1313         5      4      5        4          2.0       5.0       3.0   \n",
       "1314         5      4      1        5          1.0       5.0       4.0   \n",
       "1315         4      2      1        6          1.0       4.5       3.0   \n",
       "\n",
       "      wl_std_2  sp_std_2  wl_max_2  sp_max_2  wl_min_2  sp_min_2  wl_delta_2  \\\n",
       "1          0.0       0.0       3.0       3.0       3.0       3.0         0.0   \n",
       "2          0.0       0.0       3.0       3.0       3.0       3.0         0.0   \n",
       "3          0.0       0.0       3.0       3.0       3.0       3.0         0.0   \n",
       "4          0.0       0.0       3.0       3.0       3.0       3.0         0.0   \n",
       "5          0.0       0.0       3.0       3.0       3.0       3.0         0.0   \n",
       "...        ...       ...       ...       ...       ...       ...         ...   \n",
       "1311       0.5       1.5       5.0       5.0       4.0       2.0         1.0   \n",
       "1312       0.0       0.0       5.0       2.0       5.0       2.0         0.0   \n",
       "1313       0.0       1.0       5.0       4.0       5.0       2.0         0.0   \n",
       "1314       0.0       0.0       5.0       4.0       5.0       4.0         0.0   \n",
       "1315       0.5       1.0       5.0       4.0       4.0       2.0        -1.0   \n",
       "\n",
       "      sp_delta_2  voice_avg_2  voice_std_2  voice_max_2  voice_min_2  \\\n",
       "1            0.0          4.0          0.0          4.0          4.0   \n",
       "2            0.0          4.0          0.0          4.0          4.0   \n",
       "3            0.0          4.0          0.0          4.0          4.0   \n",
       "4            0.0          4.0          0.0          4.0          4.0   \n",
       "5            0.0          4.0          0.0          4.0          4.0   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1311        -3.0          4.5          0.5          5.0          4.0   \n",
       "1312         0.0          5.0          0.0          5.0          5.0   \n",
       "1313         2.0          5.0          0.0          5.0          5.0   \n",
       "1314         0.0          3.0          2.0          5.0          1.0   \n",
       "1315        -2.0          1.0          0.0          1.0          1.0   \n",
       "\n",
       "      voice_delta_2  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "5               0.0  \n",
       "...             ...  \n",
       "1311            1.0  \n",
       "1312            0.0  \n",
       "1313            0.0  \n",
       "1314           -4.0  \n",
       "1315            0.0  \n",
       "\n",
       "[1107 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.drop(['stress', 'date', 'duration', 'user', 'week'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.97       592\n",
      "           2       0.94      0.92      0.93       322\n",
      "           3       0.98      0.93      0.96       193\n",
      "\n",
      "    accuracy                           0.95      1107\n",
      "   macro avg       0.96      0.94      0.95      1107\n",
      "weighted avg       0.95      0.95      0.95      1107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(training_data['stress'], clf.predict(training_data.drop(['stress', 'date', 'duration', 'user', 'week'], axis=1).values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvabmpaams23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b35f28ca8490582ff8f77ff9980f59b5ef0ec07a74ec2efd5c7bfd81cb9aec3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
