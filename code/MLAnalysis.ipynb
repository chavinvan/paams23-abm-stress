{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Analysis to predict stress based on sleep and workload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.under_sampling import RandomUnderSampler, NeighbourhoodCleaningRule\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_to_predict = 'stress'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: darkorange' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "def select_classifier(clf_name):\n",
    "    if clf_name == 'LogR':\n",
    "        return LogisticRegression(max_iter=1500000, random_state=24091993)\n",
    "    elif clf_name == 'LinSVM':\n",
    "        return LinearSVC(max_iter=1500000, random_state=24091993)\n",
    "    elif clf_name == 'DT':\n",
    "        return DecisionTreeClassifier(random_state=24091993)\n",
    "    elif clf_name == 'RF':\n",
    "        return RandomForestClassifier()\n",
    "    \n",
    "\n",
    "def select_params(clf_name):\n",
    "    if clf_name == 'LogR':\n",
    "        return {'C': np.logspace(-3,2, num=10),}\n",
    "    elif clf_name == 'LinSVM':\n",
    "        return {'C': np.logspace(-3,2, num=10), }\n",
    "    elif clf_name == 'DT':\n",
    "        return {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "    elif clf_name == 'RF':\n",
    "        return {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion' :['gini', 'entropy']}\n",
    "\n",
    "\n",
    "def evaluate_easy(X, y, dataset_name, ws):\n",
    "    scores = []\n",
    "    for seed in [24091993]:\n",
    "        np.random.seed(seed)\n",
    "        for undersample_strategy in ['undersampling', 'none']:\n",
    "            if undersample_strategy == 'undersampling':\n",
    "                # define undersample strategy\n",
    "                undersample = NeighbourhoodCleaningRule(sampling_strategy='not minority')\n",
    "                # fit and apply the transform\n",
    "                X___, y___ = undersample.fit_resample(X, y)\n",
    "            else:\n",
    "                X___ = X\n",
    "                y___ = y\n",
    "\n",
    "            for scaler_name in ['Standard', 'None']:\n",
    "                if scaler_name == 'Standard':\n",
    "                    scaler = StandardScaler()\n",
    "                elif scaler_name == 'MinMax':\n",
    "                    scaler = MinMaxScaler()\n",
    "                elif scaler_name == 'Robust':\n",
    "                    scaler = RobustScaler()\n",
    "                else:\n",
    "                    scaler = None\n",
    "                if scaler is not None:\n",
    "                    X_ = scaler.fit_transform(X___)\n",
    "                else:\n",
    "                    X_ = X___\n",
    "\n",
    "                for clf_name in ['RF']:\n",
    "                    clf = select_classifier(clf_name)\n",
    "\n",
    "                    params = select_params(clf_name)\n",
    "                    grid_search = GridSearchCV(clf, params, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "                    grid_search.fit(X__, y___)\n",
    "\n",
    "                    scores.append(['None', undersample_strategy, seed, dataset_name, ws, scaler_name, clf_name, grid_search.best_params_, grid_search.best_score_,  'All'])\n",
    "    return scores\n",
    "\n",
    "\n",
    "def evaluate(X, y, dataset_name, ws):\n",
    "    scores = []\n",
    "    for seed in [24091993]:\n",
    "        np.random.seed(seed)\n",
    "        cv = StratifiedKFold(shuffle=True, n_splits=5, random_state=seed)\n",
    "        for undersample_strategy in ['undersampling', 'none']:\n",
    "            if undersample_strategy == 'undersampling':\n",
    "                # define undersample strategy\n",
    "                undersample = NeighbourhoodCleaningRule(sampling_strategy='not minority')\n",
    "                # fit and apply the transform\n",
    "                X___, y___ = undersample.fit_resample(X, y)\n",
    "            else:\n",
    "                X___ = X\n",
    "                y___ = y\n",
    "\n",
    "            for scaler_name in ['Standard', 'None']:\n",
    "                if scaler_name == 'Standard':\n",
    "                    scaler = StandardScaler()\n",
    "                elif scaler_name == 'MinMax':\n",
    "                    scaler = MinMaxScaler()\n",
    "                elif scaler_name == 'Robust':\n",
    "                    scaler = RobustScaler()\n",
    "                else:\n",
    "                    scaler = None\n",
    "                if scaler is not None:\n",
    "                    X_ = scaler.fit_transform(X___)\n",
    "                else:\n",
    "                    X_ = X___\n",
    "\n",
    "                for clf_name in ['RF']:\n",
    "                    clf = select_classifier(clf_name)\n",
    "                    for rfestrategy in ['None']:\n",
    "                        selected_features = []\n",
    "                        if rfestrategy == 'RFECV':\n",
    "                            selector = RFECV(clf, step=1, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "                            selector = selector.fit(X_, y___)\n",
    "                            X__ = selector.transform(X_)\n",
    "                            if ws > 1:\n",
    "                                selected_features = selector.get_feature_names_out(['sleep', 'workload', 'weekday', 'prev_stress', 'duration', 'wl_avg_{}'.format(ws), 'sp_avg_{}'.format(ws), 'wl_std_{}'.format(ws), 'sp_std_{}'.format(ws), 'wl_max_{}'.format(ws), 'sp_max_{}'.format(ws), 'wl_min_{}'.format(ws), 'sp_min_{}'.format(ws), 'wl_delta_{}'.format(ws), 'sp_delta_{}'.format(ws)])\n",
    "                            else:\n",
    "                                selected_features = selector.get_feature_names_out(['sleep', 'workload', 'weekday', 'prev_stress', 'duration'])\n",
    "                        else:\n",
    "                            if ws > 1:\n",
    "                                selected_features = ['sleep', 'workload', 'weekday', 'prev_stress', 'duration', 'wl_avg_{}'.format(ws), 'sp_avg_{}'.format(ws), 'wl_std_{}'.format(ws), 'sp_std_{}'.format(ws), 'wl_max_{}'.format(ws), 'sp_max_{}'.format(ws), 'wl_min_{}'.format(ws), 'sp_min_{}'.format(ws), 'wl_delta_{}'.format(ws), 'sp_delta_{}'.format(ws)]\n",
    "                            else:\n",
    "                                selected_features = ['sleep', 'workload', 'weekday', 'prev_stress', 'duration']\n",
    "                            X__ = X_\n",
    "\n",
    "                        params = select_params(clf_name)\n",
    "                        grid_search = GridSearchCV(clf, params, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "                        grid_search.fit(X__, y___)\n",
    "\n",
    "                        scores.append([rfestrategy, undersample_strategy, seed, dataset_name, ws, scaler_name, clf_name, grid_search.best_params_, grid_search.best_score_,  selected_features])\n",
    "    return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     'StudentLife' : {\n",
    "        'path' : 'data/processed/sl_processed_data.csv',\n",
    "        'train_weeks' : [13, 18],\n",
    "        'test_weeks' : [19, 19],\n",
    "    }, \"\"\"\n",
    "\n",
    "datasets = {\n",
    "\n",
    "    'FBK' : {\n",
    "        'path' : 'data/processed/fbk_processed_data.csv',\n",
    "        'train_weeks' : [45, 50],\n",
    "        'test_weeks' : [51, 51],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create additional features\n",
    "def create_features(data, window_size=2):\n",
    "    data['date'] = data['date'].astype('datetime64[ns]')\n",
    "    data['weekday'] = data['date'].dt.weekday\n",
    "    \n",
    "    # add a new column with the average value of the last two rows of other column\n",
    "    wl_sum = 0\n",
    "    sp_sum = 0\n",
    "    wl_values = []\n",
    "    sp_values = []\n",
    "    wl_delta = pd.Series(dtype='float64')\n",
    "    sp_delta = pd.Series(dtype='float64')\n",
    "    for i in range(0, window_size):\n",
    "        workload = data.groupby('user')['workload'].shift(i)\n",
    "        sleep = data.groupby('user')['sleep'].shift(i)\n",
    "        wl_sum += workload\n",
    "        wl_values.append(workload)\n",
    "        sp_sum += sleep\n",
    "        sp_values.append(sleep)\n",
    "        wl_delta = workload if wl_delta.empty else wl_delta - workload\n",
    "        sp_delta = sleep if sp_delta.empty else sp_delta - sleep\n",
    "\n",
    "    data['prev_stress'] = data.groupby('user')['stress'].shift(1)\n",
    "\n",
    "    if window_size > 1:\n",
    "        data['wl_avg_{}'.format(window_size)] = wl_sum / window_size\n",
    "        data['sp_avg_{}'.format(window_size)] = sp_sum / window_size\n",
    "        data['wl_std_{}'.format(window_size)] = np.std(wl_values, axis=0)\n",
    "        data['sp_std_{}'.format(window_size)] = np.std(sp_values, axis=0)\n",
    "        data['wl_max_{}'.format(window_size)] = np.max(wl_values, axis=0)\n",
    "        data['sp_max_{}'.format(window_size)] = np.max(sp_values, axis=0)\n",
    "        data['wl_min_{}'.format(window_size)] = np.min(wl_values, axis=0)\n",
    "        data['sp_min_{}'.format(window_size)] = np.min(sp_values, axis=0)\n",
    "        data['wl_delta_{}'.format(window_size)] = wl_delta\n",
    "        data['sp_delta_{}'.format(window_size)] = sp_delta\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_array = []\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    data = pd.read_csv(dataset['path'])\n",
    "    for ws in [2]:\n",
    "        _data = data.copy()\n",
    "        _data = create_features(_data, window_size=ws)\n",
    "        _data.dropna(how='any', inplace=True)\n",
    "\n",
    "        if ws > 1:\n",
    "            X = _data[['sleep', 'workload', 'weekday', 'prev_stress', 'duration', 'wl_avg_{}'.format(ws), 'sp_avg_{}'.format(ws), 'wl_std_{}'.format(ws), 'sp_std_{}'.format(ws), \n",
    "                  'wl_max_{}'.format(ws), 'sp_max_{}'.format(ws), 'wl_min_{}'.format(ws), 'sp_min_{}'.format(ws), 'wl_delta_{}'.format(ws), 'sp_delta_{}'.format(ws)]]\n",
    "        else:\n",
    "            X = _data[['sleep', 'workload', 'weekday', 'prev_stress']]\n",
    "        y = _data[variable_to_predict]\n",
    "        scores = evaluate(X, y, dataset_name, ws)\n",
    "\n",
    "        scores = pd.DataFrame(scores, columns=['rfe', 'undersampling', 'seed', 'dataset', 'window_size', 'scaler', 'classifier', 'gs_params', 'gs_score',  'features'])\n",
    "        scores_array.append(scores)\n",
    "\n",
    "scores = pd.concat(scores_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rfe</th>\n",
       "      <th>undersampling</th>\n",
       "      <th>seed</th>\n",
       "      <th>dataset</th>\n",
       "      <th>window_size</th>\n",
       "      <th>scaler</th>\n",
       "      <th>classifier</th>\n",
       "      <th>gs_params</th>\n",
       "      <th>gs_score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>undersampling</td>\n",
       "      <td>24091993</td>\n",
       "      <td>FBK</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 9, 'n_estim...</td>\n",
       "      <td>0.886972</td>\n",
       "      <td>[sleep, workload, weekday, prev_stress, durati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rfe  undersampling      seed dataset  window_size scaler classifier  \\\n",
       "1  None  undersampling  24091993     FBK            2   None         RF   \n",
       "\n",
       "                                           gs_params  gs_score  \\\n",
       "1  {'criterion': 'gini', 'max_depth': 9, 'n_estim...  0.886972   \n",
       "\n",
       "                                            features  \n",
       "1  [sleep, workload, weekday, prev_stress, durati...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['dataset'] == 'FBK'].query('gs_score == gs_score.max()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rfe</th>\n",
       "      <th>undersampling</th>\n",
       "      <th>seed</th>\n",
       "      <th>dataset</th>\n",
       "      <th>window_size</th>\n",
       "      <th>scaler</th>\n",
       "      <th>classifier</th>\n",
       "      <th>gs_params</th>\n",
       "      <th>gs_score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>undersampling</td>\n",
       "      <td>24091993</td>\n",
       "      <td>StudentLife</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 9, 'n_estim...</td>\n",
       "      <td>0.864528</td>\n",
       "      <td>[sleep, workload, weekday, prev_stress, durati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rfe  undersampling      seed      dataset  window_size scaler classifier  \\\n",
       "1  None  undersampling  24091993  StudentLife            2   None         RF   \n",
       "\n",
       "                                           gs_params  gs_score  \\\n",
       "1  {'criterion': 'gini', 'max_depth': 9, 'n_estim...  0.864528   \n",
       "\n",
       "                                            features  \n",
       "1  [sleep, workload, weekday, prev_stress, durati...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['dataset'] == 'StudentLife'].query('gs_score == gs_score.max()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 140}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['dataset'] == 'FBK'].query('gs_score == gs_score.max()').loc[1]['gs_params'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 160}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['dataset'] == 'StudentLife'].query('gs_score == gs_score.max()').loc[1]['gs_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031730000000000036"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.916497 - 0.884767"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvabmpaams23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b35f28ca8490582ff8f77ff9980f59b5ef0ec07a74ec2efd5c7bfd81cb9aec3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
